{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单值 RDD 操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map\n",
    "\n",
    "`map` 的用途是将 `RDD` 中的每个元素进行操作(加工), 操作后每个元素得到新的值, 使用这些新的元素生成一个新的 `RDD`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 5, 6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "data = [1, 2, 3, 4, 5, 6, 7] # 1\n",
    "rdd = sc.parallelize(data, 3) # 2\n",
    "arr = rdd.map(lambda x: x + 1).collect() #3\n",
    "print(arr) # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **创建 python 数组**: 命名为 data\n",
    "2. **创建 RDD 对象**: 使用 SparkContent 的 parallelize 方法将 data 数组分为 3 个 partitions 并返回 RDD 对象赋值给 rdd 变量. *注意: 这里用 sc 表示 SparkContent, 这是因为启动 pyspark 时, 系统自动导入了 SparkContent 类. 其实等于默认执行了 `from pyspark import SparkContent as sc`*\n",
    "3. **创建 python 数组**: 命名为 arr. 指定了一个 lambda 函数(也称之为**匿名函数**), 该函数的作用是对 rdd 中的每个元素进行加 1 操作. 最后的 collect 方法是 RDD 类的方法, 用于将一个 RDD 对象转换为 python 的 数组.\n",
    "4. **控制台输出/打印** python 数组 arr\n",
    "\n",
    "## 综合练习\n",
    "\n",
    "已知文件在hadoop文件系统的 `data/walmart.txt` 中包含 4 列信息, 是沃尔玛全国分店每天的流水, 分别表示分店ID(id), 交易量(x), 交易额(y)和利润(z), 类型均为整数, 数据举例如下\n",
    "\n",
    "|ID|交易量(x)|交易额(y)|利润(z)|\n",
    "|:--|:--|:--|:--|\n",
    "|1|23|5600|5|\n",
    "|2|30|5800|7|\n",
    "|1|27|5000|10|\n",
    "|3|24|6900|5|\n",
    "|2|45|5800|7|\n",
    "|2|28|5800|7|\n",
    "\n",
    "> 请问: 如何得到以下 SQL 等价的结算结果(假设存在表 T 中):\n",
    "\n",
    "```sql\n",
    "select id, sum(x), max(y), average(x) from T group by id;\n",
    "```\n",
    "\n",
    "> 扩展: 如何得到以下 SQL 等价的计算结果(提示, 用 reduce 算子)\n",
    "\n",
    "```sql\n",
    "select sum(x), max(y), min(z), average(x) from T;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1', '23', '5600', '5'],\n",
       " ['2', '30', '5800', '7'],\n",
       " ['1', '27', '5000', '10'],\n",
       " ['3', '24', '6900', '5'],\n",
       " ['2', '45', '5800', '7'],\n",
       " ['2', '28', '5800', '7']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from file to create RDD, RDD's partitions number is 2\n",
    "walmartRDD = sc.textFile('hdfs://hadoop:9000/data/walmart.txt', 2)\n",
    "\n",
    "# split every line to list\n",
    "walmartRDD.map(lambda line: line.split(',')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 23), ('2', 30), ('1', 27), ('3', 24), ('2', 45), ('2', 28)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tuple(id, x) x=交易量\n",
    "xRDD = walmartRDD.map(lambda line: line.split(',')) \\\n",
    "    .map(lambda row: (row[0], int(row[1])))\n",
    "xRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 5600), ('2', 5800), ('1', 5000), ('3', 6900), ('2', 5800), ('2', 5800)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tuple(id, y) y=交易额\n",
    "yRDD = walmartRDD.map(lambda line: line.split(',')) \\\n",
    "    .map(lambda row: (row[0], int(row[2])))\n",
    "yRDD.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 5), ('2', 7), ('1', 10), ('3', 5), ('2', 7), ('2', 7)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tuple(id, z) z=利润\n",
    "zRDD = walmartRDD.map(lambda line: line.split(',')) \\\n",
    "    .map(lambda row: (row[0], int(row[3])))\n",
    "zRDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 50), ('2', 103), ('3', 24)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(x) group by id\n",
    "xRDD.reduceByKey(lambda x, y: x + y) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 5600), ('2', 5800), ('3', 6900)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max(y) group by id\n",
    "# way 1\n",
    "yRDD.groupByKey() \\\n",
    "    .mapValues(max) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 5600), ('2', 5800), ('3', 6900)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max(y) group by id\n",
    "# way 2\n",
    "seqOp = (lambda x, y: y if x < y else x)\n",
    "combOp = (lambda x, y: y if x < y else x)\n",
    "yRDD.aggregateByKey(0, seqOp, combOp) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **上面有两种方法求最大值, 第二种方法在性能上要远远优于第一种**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 5), ('2', 7), ('3', 5)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min(z) group by id\n",
    "# way 1\n",
    "zRDD.groupByKey() \\\n",
    "    .mapValues(min) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 5), ('2', 7), ('3', 5)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min(z) group by id\n",
    "# way 2\n",
    "import sys\n",
    "seqOp = (lambda x, y: y if x > y else x)\n",
    "combOp = (lambda x, y: y if x > y else x)\n",
    "zRDD.aggregateByKey(sys.maxsize, seqOp, combOp) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **上面有两种方法求最大值, 第二种方法在性能上要远远优于第一种**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 25.0), ('2', 34.333333333333336), ('3', 24.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average(x) group by id\n",
    "seqOp = (lambda acc, val: (acc[0] + val, acc[1] + 1))\n",
    "combOp = (lambda p1, p2: (p1[0] + p2[0], p1[1] + p2[1]))\n",
    "\n",
    "(xRDD.aggregateByKey((0, 0), seqOp, combOp)       # retrun RDD's element's type is (id, (sum(x), count))\n",
    "    .map(lambda el: (el[0], el[1][0] / el[1][1])) # retrun RDD's element's type is (id, average)\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 扩展问题的答案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum(x)\n",
    "xRDD.map(lambda x: x[1]) \\\n",
    "    .reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6900"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max(y)\n",
    "yRDD.map(lambda x: x[1]) \\\n",
    "    .reduce(lambda x, y: x if x > y else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min(z)\n",
    "zRDD.map(lambda x: x[1]) \\\n",
    "    .reduce(lambda x, y: x if x < y else y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average(x)\n",
    "seqOp = (lambda x, y: (x[0] + y, x[1] + 1))\n",
    "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "iSum, iCount = xRDD.map(lambda x: x[1]) \\\n",
    "    .aggregate((0, 0), seqOp, combOp)\n",
    "iSum / iCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [1, 2, 3, 4]\n",
    "rdd = sc.parallelize(arr)\n",
    "seqOp = (lambda x, y: x + y)\n",
    "combOp = (lambda x, y: x + y)\n",
    "rdd.aggregate(0, seqOp, combOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当初始值不是 0 的时候, aggregate 函数的行为变得比较奇特"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregate(1, seqOp, combOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正常理解应该是 11, 即应该是 $1+1+2+3+4=11$ (其中第一个 1 是初始值), 但结果为何是 12 呢?\n",
    "\n",
    "主要原因是在 combOp 这个函数, 他最后做了 partions 的合并动作, 在进行 combin 时, 参数 x 的值 1, 即为初始化的值, 参数 y 的值是 seqOp 函数结算的结果, 这里是 11, 因此 $x+y=1+11=12$\n",
    "\n",
    "根据上面的规则, 当初始值为 5 的时候, $x+y=5+5+1+2+3+4=20$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.aggregate(5, seqOp, combOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再进一步说明:\n",
    "初始值=5 rdd 中的元素为 [1,2,3,4]\n",
    "- seqOp的计算步骤为: 初始值 + rdd = 5 + arr[1,2,3,4] = 15\n",
    "- combOp的计算步骤为: 初始值 5 + seqOp 的结果 15 = 20\n",
    "\n",
    "下面我们再试一试有 partition 的情况下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(arr, 2)\n",
    "rdd.aggregate(2, seqOp, combOp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 分区为 2 时, rdd 的值被拆分为 2 部分 [1,2] 和 [3,4]\n",
    "- seqOp 的结果是: partion 1 is $2+1+2=5$; partion 2 is $2+3+4=9$\n",
    "- combOp 的结果是: partion 1 + partion 2 + 初始值 = $5+9+2=16$\n",
    "\n",
    "整理成公式: 假设分区是 $n$, 初始值是 $m$, $z$ 是 rdd 内元素的合计结果, 则最后得到的结果 $r$ 为\n",
    "\n",
    "$r=n \\times m+m+z$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
