{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "\n",
    "## Creating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------+------+-------+\n",
      "|age|gender|occupation|userID|zipcode|\n",
      "+---+------+----------+------+-------+\n",
      "|  1|     F|        10|     1|  48067|\n",
      "| 56|     M|        16|     2|  70072|\n",
      "| 25|     M|        15|     3|  55117|\n",
      "| 45|     M|         7|     4|  02460|\n",
      "| 25|     M|        20|     5|  55455|\n",
      "| 50|     F|         9|     6|  55117|\n",
      "| 35|     M|         1|     7|  06810|\n",
      "| 25|     M|        12|     8|  11413|\n",
      "| 25|     M|        17|     9|  61614|\n",
      "| 35|     F|         1|    10|  95370|\n",
      "| 25|     F|         1|    11|  04093|\n",
      "| 25|     M|        12|    12|  32793|\n",
      "| 45|     M|         1|    13|  93304|\n",
      "| 35|     M|         0|    14|  60126|\n",
      "| 25|     M|         7|    15|  22903|\n",
      "| 35|     F|         0|    16|  20670|\n",
      "| 50|     M|         1|    17|  95350|\n",
      "| 18|     F|         3|    18|  95825|\n",
      "|  1|     M|        10|    19|  48073|\n",
      "| 25|     M|        14|    20|  55113|\n",
      "+---+------+----------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set filename(in hdfs)\n",
    "userJSONFileName = \"hdfs://hadoop:9000/data/ml-1m/users.json\"\n",
    "# read json file\n",
    "# - spark           -> pyspark.sql.SparkSession\n",
    "# - spark.read      -> pyspark.sql.DataFrameReader\n",
    "# - spark.read.json -> pyspark.sql.DataFrame\n",
    "df = spark.read.json(userJSONFileName)\n",
    "# Displays the content of the DataFrame to stdout\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untyped Dataset Operations (aka DataFrame Operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- occupation: string (nullable = true)\n",
      " |-- userID: long (nullable = true)\n",
      " |-- zipcode: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema in a tree format\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 光环练习作业\n",
    "\n",
    "- 读取文件 `ml-1m/ratings.data` 中的内容，并将其转换为 **DataFrame/Dataset**\n",
    "\n",
    "> 这道题的目的是考量从 RDD 转换为 DataFrame 的能力\n",
    "> `ml-1m/ratings.data` 文件的说明，请查看 [Ratings File Description](#RATINGS-FILE-DESCRIPTION)\n",
    "\n",
    "**思路**：为了将 RDD 转换为 DataFrame spark 提供了两种方式\n",
    "- Inferring the Schema Using Reflection\n",
    "- Programmatically Specifying the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(movieID=1193, rating=5, timestamp=978300760, userID=1),\n",
       " Row(movieID=661, rating=3, timestamp=978302109, userID=1),\n",
       " Row(movieID=914, rating=3, timestamp=978301968, userID=1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st way: Inferring the Schema Using Reflection\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# Load a text file and convert each line to a Row\n",
    "lines = sc.textFile(\"hdfs://hadoop:9000/data/ml-1m/ratings.dat\")\n",
    "parts = lines.map(lambda l: l.split(\"::\"))\n",
    "rating = parts.map(lambda p: Row(userID=int(p[0]), movieID=int(p[1]), rating=int(p[2]), timestamp=int(p[3])))\n",
    "\n",
    "# Infer the schame, and register the DataFrame as a table.\n",
    "dfRating = spark.createDataFrame(rating)\n",
    "dfRating.createOrReplaceTempView(\"rating\")\n",
    "\n",
    "# SQL can be run over DataFrames that have been registered as table.\n",
    "results = spark.sql(\"select * from rating limit 3\")\n",
    "results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+------+\n",
      "|movieID|rating|timestamp|userID|\n",
      "+-------+------+---------+------+\n",
      "|   1193|     5|978300760|     1|\n",
      "|    661|     3|978302109|     1|\n",
      "|    914|     3|978301968|     1|\n",
      "+-------+------+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userID|moiveID|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|   1193|     5|978300760|\n",
      "|     1|    661|     3|978302109|\n",
      "|     1|    914|     3|978301968|\n",
      "+------+-------+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2nd way: Programmatically Specifying the Schema\n",
    "# Import data types\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Use above parts\n",
    "rating = parts.map(lambda p: (int(p[0]), int(p[1]), int(p[2]), int(p[3])))\n",
    "\n",
    "# The schema is encoded in a string\n",
    "schemaString = \"userID moiveID rating timestamp\"\n",
    "\n",
    "fieldsRating = [StructField(fieldName, IntegerType(), True) for fieldName in schemaString.split()]\n",
    "schemaRating = StructType(fieldsRating)\n",
    "\n",
    "# Apply the schema to the RDD\n",
    "dfRating = spark.createDataFrame(rating, schemaRating)\n",
    "\n",
    "# Create a temporary view using the DataFrame\n",
    "dfRating.createOrReplaceTempView(\"rating\")\n",
    "\n",
    "# SQL can be run over DataFrames that have been registered as a table.\n",
    "results = spark.sql(\"select * from rating limit 3\")\n",
    "\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 将上面转换的 dataframe 以 Parquet 格式存储到 /tmp/ratings.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SUMMARY\n",
    "================================================================================\n",
    "\n",
    "These files contain 1,000,209 anonymous ratings of approximately 3,900 movies \n",
    "made by 6,040 MovieLens users who joined MovieLens in 2000.\n",
    "\n",
    "USAGE LICENSE\n",
    "================================================================================\n",
    "\n",
    "Neither the University of Minnesota nor any of the researchers\n",
    "involved can guarantee the correctness of the data, its suitability\n",
    "for any particular purpose, or the validity of results based on the\n",
    "use of the data set.  The data set may be used for any research\n",
    "purposes under the following conditions:\n",
    "\n",
    "     * The user may not state or imply any endorsement from the\n",
    "       University of Minnesota or the GroupLens Research Group.\n",
    "\n",
    "     * The user must acknowledge the use of the data set in\n",
    "       publications resulting from the use of the data set\n",
    "       (see below for citation information).\n",
    "\n",
    "     * The user may not redistribute the data without separate\n",
    "       permission.\n",
    "\n",
    "     * The user may not use this information for any commercial or\n",
    "       revenue-bearing purposes without first obtaining permission\n",
    "       from a faculty member of the GroupLens Research Project at the\n",
    "       University of Minnesota.\n",
    "\n",
    "If you have any further questions or comments, please contact GroupLens\n",
    "<grouplens-info@cs.umn.edu>. \n",
    "\n",
    "CITATION\n",
    "================================================================================\n",
    "\n",
    "To acknowledge use of the dataset in publications, please cite the following\n",
    "paper:\n",
    "\n",
    "F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets: History\n",
    "and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4,\n",
    "Article 19 (December 2015), 19 pages. DOI=http://dx.doi.org/10.1145/2827872\n",
    "\n",
    "\n",
    "ACKNOWLEDGEMENTS\n",
    "================================================================================\n",
    "\n",
    "Thanks to Shyong Lam and Jon Herlocker for cleaning up and generating the data\n",
    "set.\n",
    "\n",
    "FURTHER INFORMATION ABOUT THE GROUPLENS RESEARCH PROJECT\n",
    "================================================================================\n",
    "\n",
    "The GroupLens Research Project is a research group in the Department of \n",
    "Computer Science and Engineering at the University of Minnesota. Members of \n",
    "the GroupLens Research Project are involved in many research projects related \n",
    "to the fields of information filtering, collaborative filtering, and \n",
    "recommender systems. The project is lead by professors John Riedl and Joseph \n",
    "Konstan. The project began to explore automated collaborative filtering in \n",
    "1992, but is most well known for its world wide trial of an automated \n",
    "collaborative filtering system for Usenet news in 1996. Since then the project \n",
    "has expanded its scope to research overall information filtering solutions, \n",
    "integrating in content-based methods as well as improving current collaborative \n",
    "filtering technology.\n",
    "\n",
    "Further information on the GroupLens Research project, including research \n",
    "publications, can be found at the following web site:\n",
    "        \n",
    "        http://www.grouplens.org/\n",
    "\n",
    "GroupLens Research currently operates a movie recommender based on \n",
    "collaborative filtering:\n",
    "\n",
    "        http://www.movielens.org/\n",
    "\n",
    "RATINGS FILE DESCRIPTION\n",
    "================================================================================\n",
    "\n",
    "All ratings are contained in the file \"ratings.dat\" and are in the\n",
    "following format:\n",
    "\n",
    "UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "- UserIDs range between 1 and 6040 \n",
    "- MovieIDs range between 1 and 3952\n",
    "- Ratings are made on a 5-star scale (whole-star ratings only)\n",
    "- Timestamp is represented in seconds since the epoch as returned by time(2)\n",
    "- Each user has at least 20 ratings\n",
    "\n",
    "USERS FILE DESCRIPTION\n",
    "================================================================================\n",
    "\n",
    "User information is in the file \"users.dat\" and is in the following\n",
    "format:\n",
    "\n",
    "UserID::Gender::Age::Occupation::Zip-code\n",
    "\n",
    "All demographic information is provided voluntarily by the users and is\n",
    "not checked for accuracy.  Only users who have provided some demographic\n",
    "information are included in this data set.\n",
    "\n",
    "- Gender is denoted by a \"M\" for male and \"F\" for female\n",
    "- Age is chosen from the following ranges:\n",
    "\n",
    "\t*  1:  \"Under 18\"\n",
    "\t* 18:  \"18-24\"\n",
    "\t* 25:  \"25-34\"\n",
    "\t* 35:  \"35-44\"\n",
    "\t* 45:  \"45-49\"\n",
    "\t* 50:  \"50-55\"\n",
    "\t* 56:  \"56+\"\n",
    "\n",
    "- Occupation is chosen from the following choices:\n",
    "\n",
    "\t*  0:  \"other\" or not specified\n",
    "\t*  1:  \"academic/educator\"\n",
    "\t*  2:  \"artist\"\n",
    "\t*  3:  \"clerical/admin\"\n",
    "\t*  4:  \"college/grad student\"\n",
    "\t*  5:  \"customer service\"\n",
    "\t*  6:  \"doctor/health care\"\n",
    "\t*  7:  \"executive/managerial\"\n",
    "\t*  8:  \"farmer\"\n",
    "\t*  9:  \"homemaker\"\n",
    "\t* 10:  \"K-12 student\"\n",
    "\t* 11:  \"lawyer\"\n",
    "\t* 12:  \"programmer\"\n",
    "\t* 13:  \"retired\"\n",
    "\t* 14:  \"sales/marketing\"\n",
    "\t* 15:  \"scientist\"\n",
    "\t* 16:  \"self-employed\"\n",
    "\t* 17:  \"technician/engineer\"\n",
    "\t* 18:  \"tradesman/craftsman\"\n",
    "\t* 19:  \"unemployed\"\n",
    "\t* 20:  \"writer\"\n",
    "\n",
    "MOVIES FILE DESCRIPTION\n",
    "================================================================================\n",
    "\n",
    "Movie information is in the file \"movies.dat\" and is in the following\n",
    "format:\n",
    "\n",
    "MovieID::Title::Genres\n",
    "\n",
    "- Titles are identical to titles provided by the IMDB (including\n",
    "year of release)\n",
    "- Genres are pipe-separated and are selected from the following genres:\n",
    "\n",
    "\t* Action\n",
    "\t* Adventure\n",
    "\t* Animation\n",
    "\t* Children's\n",
    "\t* Comedy\n",
    "\t* Crime\n",
    "\t* Documentary\n",
    "\t* Drama\n",
    "\t* Fantasy\n",
    "\t* Film-Noir\n",
    "\t* Horror\n",
    "\t* Musical\n",
    "\t* Mystery\n",
    "\t* Romance\n",
    "\t* Sci-Fi\n",
    "\t* Thriller\n",
    "\t* War\n",
    "\t* Western\n",
    "\n",
    "- Some MovieIDs do not correspond to a movie due to accidental duplicate\n",
    "entries and/or test entries\n",
    "- Movies are mostly entered by hand, so errors and inconsistencies may exist\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
